# BoTorch Multi-Objective LLM Optimization Configuration
# This file contains all experimental settings for reproducible runs

# Optimization Parameters
optimization:
  n_initial: 16         # Number of initial random points - Increased for better exploration
  n_iterations: 15     # Number of Bayesian Optimization iterations - Increased for real testing
  batch_size: 1        # Number of candidates per iteration (q) - Keep at 1 for stability
  
# Model Parameters
model:
  num_restarts: 20     # Number of restarts for acquisition optimization
  raw_samples: 1024    # Number of raw samples for acquisition optimization
  mc_samples: 512      # Number of Monte Carlo samples for acquisition

# Bounds and Reference Point
bounds:
  lower: 0.0          # Lower bound for all dimensions
  upper: 1.0          # Upper bound for all dimensions

reference_point:
  performance: -0.1   # Reference point for performance (negative because we maximize)
  cost: 1.1          # Reference point for cost (positive because we minimize)

# Evaluation Architecture Selection
architecture: gaia_smolagents
evaluation:
  architecture: "gaia_smolagents"  # Options: "simulated", "gaia_smolagents"
  # Architecture configs loaded from multi_agent_architectures/<architecture>/config.yaml

# Agent Configuration (for simulated architecture - overridden by GAIA)
agents: # Only used in the SIMULATED architecture, the agents are specified in /gaia_smolagents/config.yaml
  n_agents: 5  # Will be overridden to 5 for GAIA architecture
  roles: ["manager", "search_agent", "text_inspector", "visual_qa", "reformulator"]
  role_to_feature:
    MMLU: 0
    HumanEval: 1
    MATH: 3

# Features to Use
features:
  - "MMLU" # Reasoning & Knowledge
  - "HumanEval" # Coding
  - "GSM8K" # Scientific Reasoning
  # - "MATH" # Quantitative Reasoning / Mathematical Reasoning
  # - "MT_bench" # Conversational Capabilities
  - "Costo_Input_1M" # Cost Optimization
  - "Costo_Output_1M" # Cost Optimization

# Data Configuration
data:
  input_file: "data/llm_data.csv"
  
# Output Configuration
output:
  save_checkpoints: true    # Save intermediate results at each iteration
  checkpoint_frequency: 1   # Save every N iterations
  
# Device Configuration
device:
  use_cuda: true           # Use GPU if available
  dtype: "double"          # Precision: "float" or "double"

# Experiment Metadata
experiment:
  name: "BoTorch_Multi_Objective_LLM"
  description: "Bayesian Optimization for LLM selection using qLogEHVI"
  version: "1.0"
